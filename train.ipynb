{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from model import YOLOv1\n",
    "from dataset import COCODataset, print_sample\n",
    "from utils import (\n",
    "    convert_cellboxes,\n",
    "    plot_image,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from train import Compose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from loss import YoloLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da51d0e06a763a57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hp = {\n",
    "    # model config\n",
    "    'S': 4,\n",
    "    'B': 2,\n",
    "    'dropout': 0.5,\n",
    "    'image_size': 256,\n",
    "    # training config\n",
    "    'lr': 2e-5,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'batch_size': 8,\n",
    "    'weight_decay': 0,\n",
    "    'num_epochs': 10,\n",
    "    'num_worker': 0,\n",
    "    'Pin_memory': True,\n",
    "    'load_model': True,\n",
    "    'load_model_file': 'overfit.pth.tar',\n",
    "    'max_training_samples': 100,\n",
    "    # loss config\n",
    "    'lambda_coord': 5,\n",
    "    'lambda_noobj': 0.5,\n",
    "    # validation config \n",
    "    'threshold':0.4,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d3285ab206a3775"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Util Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1feeea4b2b180a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def non_max_suppression(bboxes, threshold):\n",
    "    assert type(bboxes) == list\n",
    "    bboxes = [box for box in bboxes if box[0] > threshold]\n",
    "    return bboxes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9018f7be52d7c909"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cellboxes_to_boxes(out, S=hp['S']):\n",
    "    converted_pred = convert_cellboxes(out,S)\n",
    "    converted_pred = converted_pred.reshape(out.shape[0], S * S, -1)\n",
    "    return converted_pred.tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "470220f41abe5b86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels):\n",
    "    print(boxes_preds.shape)\n",
    "    print(boxes_labels.shape)\n",
    "    box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "    box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "    box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "    box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "    box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "    box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "    box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "    box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # .clamp(0) is for the case when they do not intersect\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f3abcf09b9fd55e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mean_iou(\n",
    "        loader,\n",
    "        model,\n",
    "        threshold,\n",
    "        split_size=hp['S'],\n",
    "        sample_batch_size = 10):\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    \n",
    "    for batch_idx, (x,y) in enumerate(loader):\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        if batch_idx > 10:\n",
    "            break\n",
    "        x = x.to(hp['device'])\n",
    "        y = y.to(hp['device'])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(x)\n",
    "        print(preds.shape)    \n",
    "            \n",
    "        for idx,pred in enumerate(preds):\n",
    "            print(pred.shape)\n",
    "            pred = pred.view([hp['S']*hp['S']*2,5])\n",
    "            label = y[idx].view([hp['S']*hp['S']*2,5])\n",
    "            print(pred.shape)\n",
    "            suppressed_pred = non_max_suppression(pred.tolist(),threshold)\n",
    "            print(torch.Tensor(suppressed_pred).shape)\n",
    "            iou = intersection_over_union(torch.Tensor(suppressed_pred),label)\n",
    "            ious.append(iou.item())\n",
    "            break\n",
    "        break\n",
    "        \n",
    "    return sum(ious)/len(ious)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "454f9696f68bee76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34d6b7153bb2e962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = Compose([transforms.Resize((hp['image_size'], hp['image_size'])), transforms.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6edb87f9f86b8ece"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Training Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b1a31fdd3d9976"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset_100 = COCODataset(transform=transform)\n",
    "train_dataset_100.load_dataset()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "377bd9e90b82e25a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(  dataset=train_dataset_100, batch_size=hp[\"batch_size\"], num_workers=hp[\"num_worker\"],\n",
    "                            pin_memory=hp[\"Pin_memory\"], shuffle=True, drop_last=False)\n",
    "print(f\"Train loader initialized with: batch_size={hp['batch_size']} on device: {hp['device']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "412aa3abe3c77762"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print Stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "278e1a1dd0ad2efc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_dataset_100)}\")\n",
    "# Display the first batch samples with true boxes\n",
    "for x,y in train_loader:\n",
    "    for idx in range(hp['batch_size']):\n",
    "        print(y[idx])\n",
    "        real_boxes = cellboxes_to_boxes(y.flatten(start_dim=1),hp['S'])\n",
    "        print(f\"Image shape: {x[idx].shape}\")\n",
    "        print(f\"Box shape: {len(real_boxes[idx])}\")\n",
    "        print(f\"The first Boxes are: {real_boxes[idx]}\")\n",
    "        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), real_boxes[idx])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c61afb32cf27d663"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Validation Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5d381fb607c5e00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_dataset_100 = COCODataset(transform=transform)\n",
    "val_dataset_100.load_dataset(\"validation\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfd7314773e880f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset=val_dataset_100, batch_size=hp[\"batch_size\"], num_workers=hp[\"num_worker\"],\n",
    "                          pin_memory=hp[\"Pin_memory\"], shuffle=True, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97d2cb9194b69d19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print Stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "178ac2072d64a033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation samples: {len(val_dataset_100)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5d291170d6be4ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x,y in val_loader:\n",
    "    for idx in range(hp['batch_size']):\n",
    "        real_boxes = cellboxes_to_boxes(y.flatten(start_dim=1),hp['S'])\n",
    "        print(f\"Image shape: {x[idx].shape}\")\n",
    "        print(f\"Box shape: {len(real_boxes[idx])}\")\n",
    "        print(f\"The first Boxes are: {real_boxes[idx]}\")\n",
    "        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), real_boxes[idx])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb3cbbb7ca175b10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48ebcf30b07458d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = YOLOv1().to(hp[\"device\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce17ac942f7fa1a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = torch.randn((8, 3, 256, 256))\n",
    "    print(model(x).shape)\n",
    "test()\n",
    "print(f\"Shape should be: [{hp['batch_size']}, {hp['S']*hp['S']*hp['B']*5}]\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8d2db7e743cbec7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"weight_decay\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd48aad0b008de70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = YoloLoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2dc57c71d2a6011"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intermediate_print(out):\n",
    "        for idx in range(8):\n",
    "            bboxes = cellboxes_to_boxes(out, S=hp[\"S\"])\n",
    "            plot_image(x[idx].permute(1, 2, 0).to(\"cpu\"), bboxes[idx])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3d63f8d6997ed8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_fn(train_loader,val_loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    ridx = torch.randint(0, len(train_loader), (1,)).item()\n",
    "    #------------------- Training -------------------#\n",
    "    mean_train_loss = []\n",
    "    mean_train_box_loss = []\n",
    "    mean_train_obj_loss = []\n",
    "    mean_train_noobj_loss = []\n",
    "    for batch_idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(hp[\"device\"]), y.to(hp[\"device\"])\n",
    "        out = model(x)\n",
    "        loss,box_loss,obj_loss,noobj_loss = loss_fn(out, y)\n",
    "        mean_train_loss.append(loss.item())\n",
    "        mean_train_box_loss.append(box_loss.item())\n",
    "        mean_train_obj_loss.append(obj_loss.item())\n",
    "        mean_train_noobj_loss.append(noobj_loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if batch_idx == ridx:\n",
    "            #intermediate_print(batch_idx,ridx,out)\n",
    "        # update progress bar\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Mean train loss was {sum(mean_train_loss)/len(mean_train_loss)}\")\n",
    "    print(f\"Mean train Box loss was {sum(mean_train_box_loss)/len(mean_train_box_loss)}\")\n",
    "    print(f\"Mean train Obj loss was {sum(mean_train_obj_loss)/len(mean_train_obj_loss)}\")\n",
    "    print(f\"Mean train Noobj loss was {sum(mean_train_noobj_loss)/len(mean_train_noobj_loss)}\")\n",
    "\n",
    "    #------------------- Validation -------------------#\n",
    "    model.eval()\n",
    "    mean_val_loss = []\n",
    "    mean_val_box_loss = []\n",
    "    mean_val_obj_loss = []\n",
    "    mean_val_noobj_loss = []\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in val_loader:\n",
    "            x, y = x.to(hp[\"device\"]), y.to(hp[\"device\"])\n",
    "            out = model(x)\n",
    "            loss,box_loss,obj_loss,noobj_loss = loss_fn(out, y)\n",
    "            mean_val_loss.append(loss.item())\n",
    "            mean_val_box_loss.append(box_loss.item())\n",
    "            mean_val_obj_loss.append(obj_loss.item())\n",
    "            mean_val_noobj_loss.append(noobj_loss.item())\n",
    "    model.train()\n",
    "    print(f\"Mean validation loss was {sum(mean_val_loss)/len(mean_val_loss)}\")\n",
    "    print(f\"Mean validation Box loss was {sum(mean_val_box_loss)/len(mean_val_box_loss)}\")\n",
    "    print(f\"Mean validation Obj loss was {sum(mean_val_obj_loss)/len(mean_val_obj_loss)}\")\n",
    "    print(f\"Mean validation Noobj loss was {sum(mean_val_noobj_loss)/len(mean_val_noobj_loss)}\")\n",
    "    return sum(mean_val_loss)/len(mean_val_loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db21fdfb51f0486b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_loss = 1000\n",
    "for epoch in range(hp[\"num_epochs\"]):\n",
    "    \"\"\"\n",
    "    #------------------- Training IOU -------------------#\n",
    "    train_iou = get_mean_iou(\n",
    "            train_loader, model, threshold=0.4, split_size=hp[\"S\"]\n",
    "    )\n",
    "    print(f\"Train mAP: {train_iou}\")\n",
    "    #------------------- Validation IOU -------------------#\n",
    "    val_iou = get_mean_iou(\n",
    "            train_loader, model, threshold=0.4, split_size=hp[\"S\"]\n",
    "    )\n",
    "    print(f\"Val mAP: {val_iou}\")\n",
    "    #------------------- Checkpointing -------------------#\n",
    "    if val_iou >= best_iou:\n",
    "        best_iou = val_iou\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint, filename=hp[\"load_model_file\"])\n",
    "    \"\"\"\n",
    "    #------------------- Training -------------------#\n",
    "    val_loss = train_fn(train_loader,val_loader, model, optimizer, loss_fn)\n",
    "    if val_loss >= best_loss:\n",
    "        best_loss = val_loss\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        print(\"=> Saving checkpoint\")\n",
    "        torch.save(checkpoint, hp[\"load_model_file\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd2d9a08c246bfc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24fb493f08e3cfa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f99af8170e5fb1e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validation_print(out):\n",
    "    bboxes = cellboxes_to_boxes(out, S=hp[\"S\"])\n",
    "    for idx in range(8):\n",
    "        best_boxes = non_max_suppression(bboxes[idx],hp['threshold'])\n",
    "        plot_image(x[idx].permute(1, 2, 0).to(\"cpu\"), best_boxes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2b7589cb59bffec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (x, y) in val_loader:\n",
    "        out = model(x)\n",
    "        validation_print(out)\n",
    "        break\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec82071b74f28ae0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7dcb8755a89fe855"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e8359ccce23760d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
